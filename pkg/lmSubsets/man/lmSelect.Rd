\name{lmSelect}


\alias{lmSelect}
\alias{lmSelect.default}
\alias{lmSelect.matrix}
\alias{lmSelect.lmSubsets}
\alias{lmSelect_fit}
\alias{lmSubsets_select}
\alias{print.lmSelect}
\alias{plot.lmSelect}
\alias{summary.lmSelect}
\alias{print.summary.lmSelect}


\title{Best-Subset Regression}


\description{Best-subset regression for ordinary linear models.}

\usage{
lmSelect(formula, \ldots)

\method{lmSelect}{default}(formula, data, subset, weights, na.action,
  model = TRUE, x = FALSE, y = FALSE, contrasts = NULL, offset, \ldots)

\method{lmSelect}{matrix}(formula, y, intercept = TRUE, \ldots)

\method{lmSelect}{lmSubsets}(formula, penalty = "BIC", \ldots)

lmSelect_fit(x, y, weights = NULL, offset = NULL,
  include = NULL, exclude = NULL, penalty = "BIC", tolerance = 0,
  nbest = 1, \ldots, pradius = NULL)
}


\arguments{
  \item{formula, data, subset, weights, na.action, model, x, y, contrasts,
    offset}{Standard formula interface.}
  \item{intercept}{Include intercept.}
  \item{include, exclude}{Force regressors in or out.}
  \item{penalty}{Penalty per parameter (see \code{\link[stats]{AIC}}).}
  \item{tolerance}{Approximation tolerance.}
  \item{nbest}{Number of best subsets.}
  \item{\dots}{Forwarded to \code{lmSelect_fit}.}
  \item{pradius}{Preordering radius.}
}


\details{
  The generic \code{lmSelect} computes best-variable-subset regression
  for ordinary linear models: The \code{nbest} best subset models are
  computed according to an information criterion of the AIC family (if
  the \code{penalty} argument is numeric).

  A custom selection criterion may be specified by passing an R function
  as the \code{penalty} argument.  The expected signature is
  \code{function (size, rss)}, where \code{size} is the number of
  predictors (including intercept, if any) in a submodel, and \code{rss}
  the residual sum of squares.  Furthermore, the function must be
  non-decreasing in both parameters.

  See \code{\link{lmSubsets}} for further information.
}


\value{
  An object of class \code{"lmSelect"}, i.e. a list with the following
  components:
  \item{nobs, nvar}{Number of observations, of variables.}
  \item{intercept}{\code{TRUE} if model has intercept term;
    \code{FALSE} otherwise.}
  \item{include, exclude}{Included, excluded variables.}
  \item{sizes}{Subset sizes.}
  \item{tolerance}{Approximation tolerance.}
  \item{nbest}{Number of best subsets.}
  \item{rank, df_residual}{Rank, residual degrees of freedom.}
  \item{penalty}{Penalty value.}
  \item{which}{Selected variables.}

  Further components include \code{call}, \code{na.action},
  \code{weights}, \code{offset}, \code{contrasts}, \code{xlevels},
  \code{terms}, \code{mf}, \code{x}, and \code{y}.  See
  \code{\link[stats]{lm}} for more information.
}


\references{
  Hofmann M, Gatu C, Kontoghiorghes EJ (2007).  Efficient Algorithms for
  Computing the Best Subset Regression Models for Large-Scale Problems.
  \emph{Computational Statistics \& Data Analysis}, \bold{52}, 16--29.

  Gatu C, Kontoghiorghes EJ (2006).  Branch-and-Bound Algorithms for
  Computing the Best Subset Regression Models.  \emph{Journal of
  Computational and Graphical Statistics}, \bold{15}, 139--156.
}


\seealso{\code{\link{lmSubsets}}, \code{\link{summary}},
  \link{methods}.}


\examples{
## load data (with logs for relative potentials)
data("AirPollution", package = "lmSubsets")


###################
##  basic usage  ##
###################

## fit 20 best subsets (BIC)
lm_best <- lmSelect(mortality ~ ., data = AirPollution, nbest = 20)
lm_best

## equivalent to:
\dontrun{
lm_all <- lmSubsets(mortality ~ ., data = AirPollution, nbest = 20)
lm_best <- lmSelect(lm_all)
}

## summary statistics
summary(lm_best)

## visualize
plot(lm_best)


########################
##  custom criterion  ##
########################

## the same as above, but with a custom criterion:
M <- nrow(AirPollution)

ll <- function (rss) {
  -M/2 * (log(2 * pi) - log(M) + log(rss) + 1)
}

aic <- function (size, rss, k = 2) {
  -2 * ll(rss) + k * (size + 1)
}

bic <- function (size, rss) {
  aic(size, rss, k = log(M))
}

lm_cust <- lmSelect(mortality ~ ., data = AirPollution, penalty = bic, nbest = 20)
lm_cust
}


\keyword{regression}
